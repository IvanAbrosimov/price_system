"""
Price System - –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–æ–≤
–í–µ—Ä—Å–∏—è: 5.0 (Google Drive + Telegram + Name Cache)

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ Google Drive
- –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∞–π—Å–æ–≤ –æ—Ç –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π (name_cache.xlsx)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–æ–≤
- –ó–∞–≥—Ä—É–∑–∫–∞ –≤ PostgreSQL
- –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
"""

import pandas as pd
import os
import sys
import io
import json
import requests
from typing import Dict, List, Tuple, Optional
from datetime import datetime

# Google Drive API
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

# Google Drive
GOOGLE_DRIVE_FOLDER_ID = "1oxEm8YySlfqXVQOptkOc0_Eoq3WJWL06"
CREDENTIALS_FILE = os.path.join(os.path.dirname(__file__), "google_credentials.json")

# Telegram
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "8579599270:AAE7-Ote1J1xlOKbkzF19eX4PmTTsl_ZU8I")
TELEGRAM_CHAT_IDS = os.environ.get("TELEGRAM_CHAT_IDS", "272265312").split(",")

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
INPUT_DIR = "input"
OUTPUT_DIR = "output"

# –ù—É–∂–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –∏–∑ Euroelectric.xlsx
ALLOWED_BRANDS = [
    'AirRoxy',
    'Bticino',
    'CHINT',
    'DKC',
    'IEK',
    'Jung',
    'Legrand',
    'OBO Bettermann',
    'Schneider Electric'
]

# –§–∞–π–ª—ã –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ Google Drive
DRIVE_FILES = {
    'Euroelectric.xlsx': None,
    'Axima_price.xlsx': None,
    'ostatki_Euroelectric.xlsx': None,
    'dostupnost_Euroelectric.xlsx': None,
    'settings.xlsx': None,
    'name_cache.xlsx': None,
}

# ============================================================================
# TELEGRAM –£–í–ï–î–û–ú–õ–ï–ù–ò–Ø
# ============================================================================

def send_telegram_message(message: str, parse_mode: str = "HTML"):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram"""
    if not TELEGRAM_BOT_TOKEN:
        print("‚ö†Ô∏è TELEGRAM_BOT_TOKEN –Ω–µ —É–∫–∞–∑–∞–Ω, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        return
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    
    for chat_id in TELEGRAM_CHAT_IDS:
        chat_id = chat_id.strip()
        if not chat_id:
            continue
        try:
            response = requests.post(url, json={
                "chat_id": chat_id,
                "text": message,
                "parse_mode": parse_mode
            }, timeout=10)
            if response.status_code == 200:
                print(f"  üì± Telegram: —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {chat_id}")
            else:
                print(f"  ‚ö†Ô∏è Telegram –æ—à–∏–±–∫–∞: {response.text}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Telegram –æ—à–∏–±–∫–∞: {e}")


def notify_start():
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ —Å–±–æ—Ä–∫–∏"""
    send_telegram_message("üöÄ <b>–°–±–æ—Ä–∫–∞ –ø—Ä–∞–π—Å–∞ –∑–∞–ø—É—â–µ–Ω–∞</b>\n\n–°–∫–∞—á–∏–≤–∞—é —Ñ–∞–π–ª—ã –∏–∑ Google Drive...")


def notify_success(total_products: int, duration: float):
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–π —Å–±–æ—Ä–∫–µ"""
    message = f"""‚úÖ <b>–°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!</b>

üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: <b>{total_products:,}</b>
‚è± –í—Ä–µ–º—è —Å–±–æ—Ä–∫–∏: <b>{duration:.1f} —Å–µ–∫</b>
üïê {datetime.now().strftime('%d.%m.%Y %H:%M')}"""
    send_telegram_message(message)


def notify_error(error: str):
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ"""
    message = f"""‚ùå <b>–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏!</b>

<code>{error[:500]}</code>

üïê {datetime.now().strftime('%d.%m.%Y %H:%M')}"""
    send_telegram_message(message)


# ============================================================================
# GOOGLE DRIVE
# ============================================================================

def get_drive_service(readonly: bool = True):
    """–°–æ–∑–¥–∞–µ—Ç —Å–µ—Ä–≤–∏—Å Google Drive API"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ Drive –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    scopes = ['https://www.googleapis.com/auth/drive']
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ credentials
    creds_json = os.environ.get("GOOGLE_CREDENTIALS_JSON")
    
    if creds_json:
        # Credentials –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (–¥–ª—è GitHub Actions)
        creds_dict = json.loads(creds_json)
        credentials = service_account.Credentials.from_service_account_info(
            creds_dict,
            scopes=scopes
        )
    elif os.path.exists(CREDENTIALS_FILE):
        # Credentials –∏–∑ —Ñ–∞–π–ª–∞ (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)
        credentials = service_account.Credentials.from_service_account_file(
            CREDENTIALS_FILE,
            scopes=scopes
        )
    else:
        raise FileNotFoundError(
            f"‚ùå Credentials –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!\n"
            f"–£–∫–∞–∂–∏—Ç–µ GOOGLE_CREDENTIALS_JSON –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ {CREDENTIALS_FILE}"
        )
    
    return build('drive', 'v3', credentials=credentials)


def list_drive_files(service) -> Dict[str, str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ Google Drive"""
    results = service.files().list(
        q=f"'{GOOGLE_DRIVE_FOLDER_ID}' in parents and trashed=false",
        fields="files(id, name, mimeType, modifiedTime)"
    ).execute()
    
    files = {}
    for f in results.get('files', []):
        files[f['name']] = f['id']
        print(f"  üìÑ {f['name']}")
    
    return files


def download_file_from_drive(service, file_id: str, file_name: str) -> bytes:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ Google Drive"""
    request = service.files().get_media(fileId=file_id)
    file_buffer = io.BytesIO()
    downloader = MediaIoBaseDownload(file_buffer, request)
    
    done = False
    while not done:
        status, done = downloader.next_chunk()
    
    file_buffer.seek(0)
    return file_buffer.read()


def download_all_files_from_drive() -> bool:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –∏–∑ Google Drive"""
    print("\nüì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ Google Drive...")
    
    try:
        service = get_drive_service()
        drive_files = list_drive_files(service)
        
        os.makedirs(INPUT_DIR, exist_ok=True)
        
        for file_name in DRIVE_FILES.keys():
            if file_name in drive_files:
                file_id = drive_files[file_name]
                content = download_file_from_drive(service, file_id, file_name)
                
                local_path = os.path.join(INPUT_DIR, file_name)
                with open(local_path, 'wb') as f:
                    f.write(content)
                
                print(f"  ‚úÖ {file_name} ({len(content) / 1024:.1f} KB)")
            else:
                if file_name != 'name_cache.xlsx':  # name_cache –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
                    print(f"  ‚ö†Ô∏è {file_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Google Drive")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –∏–∑ Google Drive: {e}")
        return False


def upload_file_to_drive(local_path: str, drive_filename: str) -> Optional[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞ Google Drive"""
    print(f"\nüì§ –ó–∞–≥—Ä—É–∑–∫–∞ {drive_filename} –Ω–∞ Google Drive...")
    
    try:
        service = get_drive_service(readonly=False)
        
        file_metadata = {
            'name': drive_filename,
            'parents': [GOOGLE_DRIVE_FOLDER_ID]
        }
        
        media = MediaFileUpload(
            local_path,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            resumable=True
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º
        results = service.files().list(
            q=f"name='{drive_filename}' and '{GOOGLE_DRIVE_FOLDER_ID}' in parents and trashed=false",
            fields="files(id)"
        ).execute()
        
        existing_files = results.get('files', [])
        
        if existing_files:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            file_id = existing_files[0]['id']
            file = service.files().update(
                fileId=file_id,
                media_body=media
            ).execute()
            print(f"  ‚úÖ –§–∞–π–ª –æ–±–Ω–æ–≤–ª—ë–Ω: {drive_filename}")
        else:
            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()
            print(f"  ‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω: {drive_filename}")
        
        return file.get('id')
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ Drive: {e}")
        return None


def send_telegram_file(file_path: str, caption: str = ""):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –≤ Telegram"""
    if not TELEGRAM_BOT_TOKEN:
        print("  ‚ö†Ô∏è TELEGRAM_BOT_TOKEN –Ω–µ —É–∫–∞–∑–∞–Ω")
        return
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendDocument"
    
    for chat_id in TELEGRAM_CHAT_IDS:
        chat_id = chat_id.strip()
        if not chat_id:
            continue
        try:
            with open(file_path, 'rb') as f:
                response = requests.post(
                    url,
                    data={
                        "chat_id": chat_id,
                        "caption": caption,
                        "parse_mode": "HTML"
                    },
                    files={"document": f},
                    timeout=120
                )
            if response.status_code == 200:
                print(f"  üì± Telegram: —Ñ–∞–π–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ {chat_id}")
            else:
                print(f"  ‚ö†Ô∏è Telegram –æ—à–∏–±–∫–∞: {response.text}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Telegram –æ—à–∏–±–∫–∞: {e}")


# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================================

def clean(x):
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    if isinstance(x, str):
        return x.strip()
    return x


def safe_float(x):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float"""
    try:
        if pd.isna(x):
            return None
        return float(x)
    except:
        return None


# ============================================================================
# –ö–≠–® –ù–ê–ò–ú–ï–ù–û–í–ê–ù–ò–ô
# ============================================================================

def load_name_cache() -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –∏–∑ name_cache.xlsx"""
    cache_file = os.path.join(INPUT_DIR, "name_cache.xlsx")
    cache = {}
    
    if not os.path.exists(cache_file):
        print("  ‚ÑπÔ∏è –§–∞–π–ª name_cache.xlsx –Ω–µ –Ω–∞–π–¥–µ–Ω, –∫—ç—à –ø—É—Å—Ç–æ–π")
        return cache
    
    try:
        df = pd.read_excel(cache_file)
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º
        article_col = None
        name_col = None
        
        for col in df.columns:
            col_lower = str(col).lower()
            if '–∞—Ä—Ç–∏–∫—É–ª' in col_lower or 'article' in col_lower:
                article_col = col
            elif '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' in col_lower or 'name' in col_lower or '–Ω–∞–∑–≤–∞–Ω–∏–µ' in col_lower:
                name_col = col
        
        if article_col is None or name_col is None:
            print(f"  ‚ö†Ô∏è –í name_cache.xlsx –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –ê—Ä—Ç–∏–∫—É–ª/–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ")
            print(f"     –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            return cache
        
        for _, row in df.iterrows():
            article = row[article_col]
            name = row[name_col]
            
            if pd.notna(article) and pd.notna(name):
                article_key = str(article).strip().lower()
                cache[article_key] = str(name).strip()
        
        print(f"  üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(cache)} –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –∏–∑ –∫—ç—à–∞")
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ name_cache.xlsx: {e}")
    
    return cache


# ============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –ù–ê–°–¢–†–û–ï–ö
# ============================================================================

def load_settings() -> Tuple[Dict, Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ settings.xlsx"""
    settings_file = os.path.join(INPUT_DIR, "settings.xlsx")
    
    if not os.path.exists(settings_file):
        raise FileNotFoundError(
            f"‚ùå –§–∞–π–ª {settings_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!\n"
            "–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≤ –ø–∞–ø–∫–µ input/"
        )
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings_raw = pd.read_excel(settings_file, sheet_name='Settings')
    settings_dict = {}
    for _, row in settings_raw.iterrows():
        param = row['parameter']
        value = row['value']
        settings_dict[param] = value
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Ä–∂—É
    margins_by_mfr = pd.read_excel(settings_file, sheet_name='Margins_by_Manufacturer')
    margins_by_art = pd.read_excel(settings_file, sheet_name='Margins_by_Article')
    
    margins_dict = {
        'global_margin': settings_dict.get('global_margin', 0.6),
        'by_manufacturer': {},
        'by_article': {}
    }
    
    for _, row in margins_by_mfr.iterrows():
        if not pd.isna(row['manufacturer']) and not pd.isna(row['margin']):
            margins_dict['by_manufacturer'][row['manufacturer']] = float(row['margin'])
    
    for _, row in margins_by_art.iterrows():
        if not pd.isna(row['article']) and not pd.isna(row['margin']):
            margins_dict['by_article'][str(row['article'])] = float(row['margin'])
    
    return settings_dict, margins_dict


def validate_settings(settings_dict: Dict):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"""
    required = ['kurs', 'global_margin']
    
    for param in required:
        if param not in settings_dict or pd.isna(settings_dict[param]):
            raise ValueError(
                f"‚ùå –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä '{param}' –Ω–µ —É–∫–∞–∑–∞–Ω –≤ settings.xlsx!"
            )
    
    print("‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø–æ–ª–Ω–µ–Ω—ã")


# ============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –û–°–¢–ê–¢–ö–û–í
# ============================================================================

def load_stock() -> Tuple[Dict, Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Å—Ç–∞—Ç–∫–∏ –∏–∑ –ê–ª–º–∞—Ç—ã –∏ –ê—Å—Ç–∞–Ω—ã"""
    almaty_file = os.path.join(INPUT_DIR, "ostatki_Euroelectric.xlsx")
    astana_file = os.path.join(INPUT_DIR, "dostupnost_Euroelectric.xlsx")
    
    almaty_stock = {}
    astana_stock = {}
    
    if os.path.exists(almaty_file):
        df = pd.read_excel(almaty_file, header=None)
        for i in range(12, len(df)):
            row = df.iloc[i]
            if len(row) > 10:
                article = clean(row.iloc[0])
                if isinstance(article, str):
                    article = article.lower()
                qty = safe_float(row.iloc[10])
                if article and qty is not None and qty > 0:
                    almaty_stock[article] = almaty_stock.get(article, 0) + qty
        print(f"  üì¶ –ê–ª–º–∞—Ç—ã: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(almaty_stock)} –ø–æ–∑–∏—Ü–∏–π")
    else:
        print(f"  ‚ö†Ô∏è –§–∞–π–ª {almaty_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if os.path.exists(astana_file):
        df = pd.read_excel(astana_file, header=None)
        for i in range(8, len(df)):
            row = df.iloc[i]
            if len(row) > 7:
                article = clean(row.iloc[0])
                if isinstance(article, str):
                    article = article.lower()
                qty = safe_float(row.iloc[7])
                if article and qty is not None and qty > 0:
                    astana_stock[article] = astana_stock.get(article, 0) + qty
        print(f"  üì¶ –ê—Å—Ç–∞–Ω–∞: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(astana_stock)} –ø–æ–∑–∏—Ü–∏–π")
    else:
        print(f"  ‚ö†Ô∏è –§–∞–π–ª {astana_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return almaty_stock, astana_stock


def determine_lead_time(article: str, almaty: Dict, astana: Dict) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏ –ø–æ –Ω–∞–ª–∏—á–∏—é"""
    astana_qty = astana.get(article, 0)
    almaty_qty = almaty.get(article, 0)
    
    if astana_qty > 0:
        return "6-10 –¥–Ω–µ–π"
    if almaty_qty > 0:
        return "10-14 –¥–Ω–µ–π"
    return "–ø–æ –∑–∞–ø—Ä–æ—Å—É"


# ============================================================================
# –ü–ê–†–°–ò–ù–ì EUROELECTRIC
# ============================================================================

def parse_euroelectric(almaty: Dict, astana: Dict, name_cache: Dict) -> List[Dict]:
    """–ü–∞—Ä—Å–∏—Ç –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª Euroelectric.xlsx —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π"""
    main_file = os.path.join(INPUT_DIR, "Euroelectric.xlsx")
    
    if not os.path.exists(main_file):
        print(f"‚ö†Ô∏è –§–∞–π–ª {main_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º EuroElectric")
        return []
    
    df = pd.read_excel(main_file)
    all_products = []
    brand_counts = {}
    cache_hits = 0
    missing_names = 0
    
    for i, row in df.iterrows():
        brand = clean(row.iloc[4]) if len(row) > 4 else None
        
        if not brand or brand not in ALLOWED_BRANDS:
            continue
        
        article_raw = clean(row.iloc[0]) if len(row) > 0 else None
        name = clean(row.iloc[1]) if len(row) > 1 else None
        rrc = safe_float(row.iloc[3]) if len(row) > 3 else None
        
        if not article_raw or rrc is None or rrc <= 0:
            continue
        
        article = article_raw.lower() if isinstance(article_raw, str) else str(article_raw).lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –µ—Å–ª–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ
        if not name or pd.isna(name) or str(name).strip() == '':
            cached_name = name_cache.get(article)
            if cached_name:
                name = cached_name
                cache_hits += 1
            else:
                name = f"[{article_raw}]"  # –í—Ä–µ–º–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                missing_names += 1
        
        dealer_price_kzt = round(rrc * 0.6, 2)
        lead_time = determine_lead_time(article, almaty, astana)
        
        all_products.append({
            'manufacturer': brand,
            'article': article,
            'name': name,
            'dealer_price_kzt': dealer_price_kzt,
            'srok': lead_time,
            'catalog_url': '',
            'image_url': ''
        })
        
        brand_counts[brand] = brand_counts.get(brand, 0) + 1
    
    print(f"  üìã –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ EuroElectric: {len(all_products)}")
    print(f"  üìö –ò–∑ –∫—ç—à–∞: {cache_hits} | –ë–µ–∑ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {missing_names}")
    for brand in sorted(brand_counts.keys()):
        print(f"     ‚Ä¢ {brand}: {brand_counts[brand]}")
    
    return all_products


# ============================================================================
# –ü–ê–†–°–ò–ù–ì AXIMA (WAGO)
# ============================================================================

def parse_axima() -> List[Dict]:
    """–ü–∞—Ä—Å–∏—Ç –ø—Ä–∞–π—Å Axima (Wago)"""
    axima_file = os.path.join(INPUT_DIR, "Axima_price.xlsx")
    
    if not os.path.exists(axima_file):
        print(f"‚ö†Ô∏è –§–∞–π–ª {axima_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º Axima")
        return []
    
    df = pd.read_excel(axima_file, header=None)
    products = []
    
    for i in range(3, len(df)):
        row = df.iloc[i]
        
        article = clean(row.iloc[0]) if len(row) > 0 else None
        name = clean(row.iloc[7]) if len(row) > 7 else None
        price = safe_float(row.iloc[13]) if len(row) > 13 else None
        
        if not article or not name or price is None or price <= 0:
            continue
        
        products.append({
            'manufacturer': 'Wago',
            'article': article,
            'name': name,
            'dealer_price_kzt': price,
            'srok': '10-14 –¥–Ω–µ–π',
            'catalog_url': '',
            'image_url': ''
        })
    
    print(f"  ‚úÖ Wago: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
    return products


# ============================================================================
# –ì–ï–ù–ï–†–ê–¶–ò–Ø EXCEL –§–ê–ô–õ–û–í
# ============================================================================

def generate_internal(products: List[Dict]) -> Tuple[str, str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø—Ä–∞–π—Å —Å –¥–∏–ª–µ—Ä—Å–∫–∏–º–∏ —Ü–µ–Ω–∞–º–∏
    
    Returns:
        (local_path, filename_with_date)
    """
    df = pd.DataFrame(products)
    df = df.sort_values(['manufacturer', 'article'])
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # –ò–º—è —Ñ–∞–π–ª–∞ —Å –¥–∞—Ç–æ–π
    date_str = datetime.now().strftime('%Y-%m-%d')
    filename = f"INTERNAL_{date_str}.xlsx"
    output_path = os.path.join(OUTPUT_DIR, filename)
    
    df.to_excel(output_path, index=False)
    
    print(f"‚úÖ {filename} —Å–æ–∑–¥–∞–Ω ({len(df)} —Ç–æ–≤–∞—Ä–æ–≤)")
    return output_path, filename


def get_margin(article: str, manufacturer: str, margins_dict: Dict) -> float:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ä–∂—É —Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
    if article in margins_dict['by_article']:
        return margins_dict['by_article'][article]
    if manufacturer in margins_dict['by_manufacturer']:
        return margins_dict['by_manufacturer'][manufacturer]
    return margins_dict['global_margin']


def calculate_client_price(dealer_price_kzt: float, article: str, manufacturer: str,
                          kurs: float, margins_dict: Dict) -> int:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç—Å–∫—É—é —Ü–µ–Ω—É –≤ —Ä—É–±–ª—è—Ö"""
    margin = get_margin(article, manufacturer, margins_dict)
    client_price_rub = (dealer_price_kzt * (1 + margin)) / kurs
    return round(client_price_rub)


def generate_public(products: List[Dict], settings_dict: Dict, margins_dict: Dict) -> Tuple[pd.DataFrame, str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π –ø—Ä–∞–π—Å —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏ –≤ —Ä—É–±–ª—è—Ö"""
    kurs = settings_dict['kurs']
    
    public_data = []
    for p in products:
        client_price = calculate_client_price(
            p['dealer_price_kzt'],
            p['article'],
            p['manufacturer'],
            kurs,
            margins_dict
        )
        
        public_data.append({
            '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å': p['manufacturer'],
            '–ê—Ä—Ç–∏–∫—É–ª': p['article'],
            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': p['name'],
            '–¶–µ–Ω–∞, —Ä—É–±': client_price,
            '–°—Ä–æ–∫ –ø–æ—Å—Ç–∞–≤–∫–∏': p['srok'],
            'catalog_url': p['catalog_url'],
            'image_url': p['image_url']
        })
    
    df = pd.DataFrame(public_data)
    df = df.sort_values(['–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å', '–ê—Ä—Ç–∏–∫—É–ª'])
    
    output_path = os.path.join(OUTPUT_DIR, "PUBLIC.xlsx")
    df.to_excel(output_path, index=False)
    
    print(f"‚úÖ PUBLIC.xlsx —Å–æ–∑–¥–∞–Ω ({len(df)} —Ç–æ–≤–∞—Ä–æ–≤)")
    return df, output_path


# ============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –í POSTGRESQL
# ============================================================================

def upload_to_postgresql(products: List[Dict], settings_dict: Dict, 
                         almaty_stock: Dict, astana_stock: Dict, 
                         margins_dict: Dict) -> bool:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL –¥–ª—è –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    try:
        import psycopg2
        from psycopg2.extras import execute_values
    except ImportError:
        print("‚ùå –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ psycopg2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
        return False
    
    database_url = os.environ.get('DATABASE_URL') or settings_dict.get('database_url')
    
    if not database_url:
        print("‚ùå DATABASE_URL –Ω–µ —É–∫–∞–∑–∞–Ω!")
        return False
    
    print("\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –≤ PostgreSQL...")
    
    try:
        conn = psycopg2.connect(database_url)
        cur = conn.cursor()
        
        kurs = settings_dict.get('kurs', 5)
        
        cur.execute("""
            CREATE TABLE IF NOT EXISTS products (
                id SERIAL PRIMARY KEY,
                manufacturer VARCHAR(255) NOT NULL,
                article VARCHAR(255) NOT NULL,
                name TEXT NOT NULL,
                price_rub INTEGER NOT NULL,
                lead_time_default VARCHAR(50),
                astana_qty INTEGER DEFAULT 0,
                almaty_qty INTEGER DEFAULT 0,
                catalog_url TEXT,
                image_url TEXT,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cur.execute("CREATE INDEX IF NOT EXISTS idx_products_manufacturer ON products(manufacturer)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_products_article ON products(article)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_products_manufacturer_article ON products(manufacturer, article)")
        
        cur.execute("TRUNCATE TABLE products RESTART IDENTITY")
        print("  üóëÔ∏è –¢–∞–±–ª–∏—Ü–∞ products –æ—á–∏—â–µ–Ω–∞")
        
        insert_data = []
        for p in products:
            article = p['article'].lower() if isinstance(p['article'], str) else str(p['article'])
            
            margin = get_margin(article, p['manufacturer'], margins_dict)
            price_rub = round((p['dealer_price_kzt'] * (1 + margin)) / kurs)
            
            astana_qty = int(astana_stock.get(article, 0))
            almaty_qty = int(almaty_stock.get(article, 0))
            lead_time = p.get('srok') or determine_lead_time(article, almaty_stock, astana_stock)
            
            insert_data.append((
                p['manufacturer'],
                article,
                p['name'],
                price_rub,
                lead_time,
                astana_qty,
                almaty_qty,
                p.get('catalog_url', ''),
                p.get('image_url', '')
            ))
        
        insert_query = """
            INSERT INTO products 
            (manufacturer, article, name, price_rub, lead_time_default, 
             astana_qty, almaty_qty, catalog_url, image_url)
            VALUES %s
        """
        
        execute_values(cur, insert_query, insert_data, page_size=500)
        conn.commit()
        
        cur.execute("SELECT COUNT(*) FROM products")
        count = cur.fetchone()[0]
        
        cur.close()
        conn.close()
        
        print(f"  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {count} —Ç–æ–≤–∞—Ä–æ–≤")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ PostgreSQL: {e}")
        return False


# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import time
    start_time = time.time()
    
    print("=" * 70)
    print("üöÄ PRICE SYSTEM v5.0 (Google Drive + Telegram + Name Cache)")
    print("=" * 70)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    use_google_drive = os.environ.get('USE_GOOGLE_DRIVE', 'true').lower() == 'true'
    
    try:
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å—Ç–∞—Ä—Ç–µ
        notify_start()
        
        # 1. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ Google Drive (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if use_google_drive:
            if not download_all_files_from_drive():
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã –∏–∑ Google Drive")
        else:
            print("\nüìÇ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ input/")
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π
        print("\nüìö –ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π...")
        name_cache = load_name_cache()
        
        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        print("\nüìã –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫...")
        settings_dict, margins_dict = load_settings()
        validate_settings(settings_dict)
        
        # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
        print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤...")
        almaty_stock, astana_stock = load_stock()
        
        # 5. –ü–∞—Ä—Å–∏–Ω–≥ EuroElectric
        print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ EuroElectric...")
        euro_products = parse_euroelectric(almaty_stock, astana_stock, name_cache)
        
        # 6. –ü–∞—Ä—Å–∏–Ω–≥ Axima (Wago)
        print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ Axima (Wago)...")
        wago_products = parse_axima()
        
        # 7. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        all_products = euro_products + wago_products
        print(f"\nüìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
        
        if len(all_products) == 0:
            raise Exception("–ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        
        # 8. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel —Ñ–∞–π–ª–∞ (—Ç–æ–ª—å–∫–æ INTERNAL —Å –¥–∞—Ç–æ–π)
        print("\nüíæ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel —Ñ–∞–π–ª–∞...")
        internal_path, internal_filename = generate_internal(all_products)
        
        # 9. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ PostgreSQL
        print("\nüêò –ó–∞–≥—Ä—É–∑–∫–∞ –≤ PostgreSQL...")
        success = upload_to_postgresql(all_products, settings_dict, almaty_stock, astana_stock, margins_dict)
        
        # 10. –ó–∞–≥—Ä—É–∑–∫–∞ INTERNAL –Ω–∞ Google Drive (–±–µ–∑ –¥–∞—Ç—ã, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –æ–±–Ω–æ–≤–ª—è—Ç—å)
        if use_google_drive:
            upload_file_to_drive(internal_path, "INTERNAL.xlsx")
        
        # –ü–æ–¥—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
        duration = time.time() - start_time
        
        print("\n" + "=" * 70)
        print("‚úÖ –í–°–ï –ì–û–¢–û–í–û!")
        print(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f} —Å–µ–∫")
        print("=" * 70)
        
        # 11. –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
        if success:
            caption = f"""‚úÖ <b>–°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!</b>

üìä –¢–æ–≤–∞—Ä–æ–≤: <b>{len(all_products):,}</b>
‚è± –í—Ä–µ–º—è: <b>{duration:.1f} —Å–µ–∫</b>
üïê {datetime.now().strftime('%d.%m.%Y %H:%M')}"""
            
            send_telegram_file(internal_path, caption)
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        notify_error(str(e))
        sys.exit(1)


if __name__ == "__main__":
    main()
